# æ•°æ®ç§‘å­¦é¡¹ç›®å®æˆ˜æŒ‡å—

"Talk is cheap. Show me the code." â€”â€” è¿™ä»½æŒ‡å—æ—¨åœ¨ä¸ºæ‚¨æä¾›ä¸€ä¸ªä»æ•°æ®å‡†å¤‡åˆ°æ¨¡å‹éƒ¨ç½²çš„å®Œæ•´ã€æ¸…æ™°ä¸”å¯æ“ä½œçš„æµç¨‹ã€‚

### ğŸ›  ç¯å¢ƒæ­å»º

ä¸ºäº†é¡ºåˆ©è¿›è¡Œæ•°æ®åˆ†æå’Œå»ºæ¨¡ï¼Œæ¨èä½¿ç”¨ **Anaconda**ï¼Œå®ƒé›†æˆäº† Python ç¯å¢ƒå’Œä¼—å¤šå¸¸ç”¨çš„æ•°æ®ç§‘å­¦åº“ã€‚

- **ä¸‹è½½ä¸å®‰è£…**: è®¿é—® Anaconda å®˜æ–¹ç½‘ç«™ä¸‹è½½å¹¶å®‰è£…é€‚åˆæ‚¨æ“ä½œç³»ç»Ÿçš„ç‰ˆæœ¬ã€‚
  - https://www.anaconda.com/download/

### 1ï¸âƒ£ æ•°æ®é¢„å¤„ç† (Data Preprocessing)

è¿™æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€è€—æ—¶ä½†è‡³å…³é‡è¦çš„ä¸€æ­¥ï¼Œé«˜è´¨é‡çš„æ•°æ®æ˜¯æ¨¡å‹æˆåŠŸçš„åŸºçŸ³ã€‚

#### 1.1 æ•°æ®å‡†å¤‡

- **è·å–æ•°æ®é›†**: æ•°æ®å¯ä»¥æ¥è‡ªå¤šç§æ¸ é“ã€‚

  - **å®˜æ–¹æœºæ„**: æ”¿åºœã€ç§‘ç ”æœºæ„å‘å¸ƒçš„æ•°æ®é›†ã€‚
  - **ç«èµ›å¹³å°**: Kaggle, å¤©æ± ç­‰ã€‚
  - **å­¦æœ¯èµ„æº**: UCI æœºå™¨å­¦ä¹ æ•°æ®åº“ç­‰ã€‚
  - **ç½‘ç»œçˆ¬è™«**: è‡ªè¡Œç¼–å†™çˆ¬è™«ä»ç½‘ç«™æŠ“å–ã€‚

- **å¯¼å…¥æ ¸å¿ƒæ¨¡å—**: å¼€å§‹ç¼–ç å‰ï¼Œé¦–å…ˆå¯¼å…¥é¡¹ç›®æ‰€éœ€çš„åŸºç¡€åº“ã€‚

  ```python
  import pandas as pd
  import numpy as np
  import matplotlib.pyplot as plt
  import seaborn as sns
  import warnings
  
  # å¿½ç•¥ä¸å¿…è¦çš„è­¦å‘Šä¿¡æ¯
  warnings.filterwarnings("ignore")
  
  # è®¾ç½®å¯è§†åŒ–æ ·å¼
  sns.set_style('whitegrid')
  
  # è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
  plt.rcParams['font.sans-serif'] = ['SimHei'] # æˆ–è€… 'Songti SC', 'Microsoft YaHei'
  plt.rcParams['axes.unicode_minus'] = False # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
  ```

- **è¯»å–ä¸ç†è§£æ•°æ®**:

  - **è¯»å–**: ä½¿ç”¨ Pandas è¯»å–æ•°æ®æ–‡ä»¶ã€‚

  ```python
  # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©åˆé€‚çš„è¯»å–å‡½æ•°
  df = pd.read_csv('your_data.csv')
  # df = pd.read_excel('your_data.xlsx')
  ```

  - **åˆæ­¥æ¢æŸ¥**: å¿«é€Ÿäº†è§£æ•°æ®çš„åŸºæœ¬æƒ…å†µã€‚

  ```python
  # æŸ¥çœ‹æ•°æ®ç»´åº¦ (è¡Œæ•°, åˆ—æ•°)
  print(df.shape)
  
  # æŸ¥çœ‹å‰5è¡Œæ•°æ®
  print(df.head())
  
  # æŸ¥çœ‹æ•°æ®åŸºæœ¬ä¿¡æ¯ (åˆ—å, éç©ºå€¼æ•°é‡, æ•°æ®ç±»å‹)
  print(df.info())
  
  # æŸ¥çœ‹æ•°å€¼å‹ç‰¹å¾çš„æè¿°æ€§ç»Ÿè®¡
  print(df.describe())
  
  # æŸ¥çœ‹ç¦»æ•£å‹ç‰¹å¾çš„æè¿°æ€§ç»Ÿè®¡
  print(df.describe(include=['object']))
  ```

  - **æ˜ç¡®ç›®æ ‡**: ç†è§£æ¯ä¸ªç‰¹å¾ï¼ˆè‡ªå˜é‡ï¼‰çš„ä¸šåŠ¡å«ä¹‰ï¼Œå¹¶ç¡®å®šè¦é¢„æµ‹æˆ–åˆ†æçš„ç›®æ ‡å˜é‡ï¼ˆå› å˜é‡ï¼‰ã€‚
  - è‡ªå˜é‡ï¼ˆXï¼‰ä¸ å› å˜é‡ï¼ˆyï¼‰

#### 1.2 æ•°æ®æ¸…æ´—

- **é‡å¤å€¼å¤„ç†**:

  - **æ£€æŸ¥**:

  ```python
  # æ£€æŸ¥æ˜¯å¦å­˜åœ¨é‡å¤è¡Œ
  print(f"é‡å¤è¡Œæ•°é‡: {df.duplicated().sum()}")
  ```

  - **å¤„ç†**:

  ```python
  # åˆ é™¤é‡å¤è¡Œï¼Œå¹¶ç›´æ¥åœ¨åŸDataFrameä¸Šä¿®æ”¹
  df.drop_duplicates(inplace=True)
  ```

- **ç¼ºå¤±å€¼å¤„ç†**:

  - **æ£€æŸ¥**:

  ```python
  # æŸ¥çœ‹æ¯åˆ—çš„ç¼ºå¤±å€¼æ•°é‡
  print(df.isnull().sum())
  
  # æ£€æŸ¥æ•°æ®é›†ä¸­æ˜¯å¦å­˜åœ¨ä»»ä½•ç¼ºå¤±å€¼
  print(df.isnull().values.any())
  ```

  - **å¤„ç†ç­–ç•¥**:

    1. **åˆ é™¤**: å½“ç¼ºå¤±æ ·æœ¬å æ¯”è¾ƒé«˜ï¼Œæˆ–è¯¥ç‰¹å¾ä¸é‡è¦æ—¶ã€‚

       ```python
       # åˆ é™¤æ‰€æœ‰åŒ…å«ç¼ºå¤±å€¼çš„è¡Œ
       df_dropped_rows = df.dropna()
       
       # åˆ é™¤æ‰€æœ‰åŒ…å«ç¼ºå¤±å€¼çš„åˆ—
       df_dropped_cols = df.dropna(axis=1)
       
       # åˆ é™¤ç‰¹å®šåˆ—
       # df.drop('column_name', axis=1, inplace=True)
       ```

    2. **å¡«è¡¥**:

       - **å¸¸æ•°å¡«å……**:

       ```python
       df_filled_zero = df.fillna(value=0)
       ```

       - **å‰/åå‘å¡«å……**: é€‚ç”¨äºæ—¶é—´åºåˆ—æ•°æ®ã€‚

       ```python
       # ä½¿ç”¨å‰ä¸€ä¸ªéç¼ºå¤±å€¼å¡«å……
       df_ffilled = df.fillna(method='ffill')
       # ä½¿ç”¨åä¸€ä¸ªéç¼ºå¤±å€¼å¡«å……
       df_bfilled = df.fillna(method='bfill')
       ```

       - **ç»Ÿè®¡å€¼å¡«å…… (æœ€å¸¸ç”¨)**:

       ```python
       # ä½¿ç”¨å­—å…¸ä¸ºä¸åŒåˆ—æŒ‡å®šä¸åŒçš„å¡«å……å€¼
       fill_values = {
           'age': df['age'].mean(),         # å‡å€¼å¡«å……å¹´é¾„
           'income': df['income'].median(),   # ä¸­ä½æ•°å¡«å……æ”¶å…¥
           'gender': df['gender'].mode()[0]  # ä¼—æ•°å¡«å……æ€§åˆ«
       }
       df.fillna(value=fill_values, inplace=True)
       ```

- **å¼‚å¸¸å€¼å¤„ç†**:

  - **è§‚å¯Ÿ**: ä½¿ç”¨ç®±çº¿å›¾æˆ–æ•£ç‚¹å›¾å¯ä»¥ç›´è§‚åœ°å‘ç°å¼‚å¸¸ç‚¹ã€‚

  ```python
  # ä½¿ç”¨ç®±çº¿å›¾è§‚å¯Ÿ'age'ç‰¹å¾çš„åˆ†å¸ƒå’Œå¼‚å¸¸ç‚¹
  sns.boxplot(x=df['age'])
  plt.title('å¹´é¾„ç‰¹å¾ç®±çº¿å›¾')
  plt.show()
  ```

  - **å¤„ç†**: å¼‚å¸¸å€¼çš„å¤„ç†éœ€ç»“åˆä¸šåŠ¡ç†è§£ï¼Œå¯ä»¥æ˜¯åˆ é™¤ã€æ›¿æ¢æˆ–è§†ä¸ºç‰¹æ®Šæƒ…å†µã€‚

### 2ï¸âƒ£ æ•°æ®åˆ†æ (Exploratory Data Analysis, EDA)

é€šè¿‡æ¢ç´¢æ€§åˆ†æå’Œå¯è§†åŒ–ï¼Œæ·±å…¥æŒ–æ˜æ•°æ®èƒŒåçš„è§„å¾‹å’Œå…³è”ã€‚

#### 2.1 æ¢ç´¢æ€§åˆ†æ

- **âœ…** **è¿ç»­å‹æ•°æ®**: æŸ¥çœ‹å…¶åˆ†å¸ƒã€ä¸­å¿ƒè¶‹åŠ¿ã€ç¦»æ•£ç¨‹åº¦ã€‚
- **âœ…** **ç¦»æ•£å‹æ•°æ®**: æŸ¥çœ‹å…¶ç±»åˆ«ã€é¢‘æ¬¡ã€å æ¯”ã€‚

#### 2.2 æ•°æ®å¯è§†åŒ–

- **è¿ç»­å‹æ•°æ®**:

  - **ç›´æ–¹å›¾ä¸æ ¸å¯†åº¦å›¾**: æŸ¥çœ‹å•å˜é‡åˆ†å¸ƒã€‚

  ```python
  sns.histplot(df['age'], kde=True)
  plt.title('å¹´é¾„åˆ†å¸ƒ')
  plt.show()
  ```

  - **æ•£ç‚¹å›¾**: æŸ¥çœ‹ä¸¤ä¸ªè¿ç»­å˜é‡é—´çš„å…³ç³»ã€‚

  ```python
  sns.scatterplot(x='age', y='income', data=df)
  plt.title('å¹´é¾„ä¸æ”¶å…¥å…³ç³»')
  plt.show()
  ```

  - **ç®±çº¿å›¾/å°æç´å›¾**: æ¯”è¾ƒä¸åŒç±»åˆ«ä¸‹è¿ç»­å˜é‡çš„åˆ†å¸ƒã€‚

  ```python
  sns.boxplot(x='gender', y='income', data=df)
  plt.title('ä¸åŒæ€§åˆ«çš„æ”¶å…¥åˆ†å¸ƒ')
  plt.show()
  ```

  - **çƒ­åŠ›å›¾**: å±•ç¤ºå¤šä¸ªè¿ç»­å˜é‡é—´çš„ç›¸å…³æ€§ã€‚

  ```python
  # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
  corr_matrix = df.corr(numeric_only=True)
  sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
  plt.title('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾')
  plt.show()
  ```

- **ç¦»æ•£å‹æ•°æ®**:

  - **æŸ±çŠ¶å›¾**: æ¯”è¾ƒä¸åŒç±»åˆ«çš„æ•°é‡ã€‚

  ```python
  sns.countplot(x='education_level', data=df)
  plt.title('ä¸åŒæ•™è‚²æ°´å¹³äººæ•°')
  plt.xticks(rotation=45)
  plt.show()
  ```

  - **é¥¼å›¾**: å±•ç¤ºä¸åŒç±»åˆ«çš„å æ¯”ã€‚

  ```python
  df['gender'].value_counts().plot.pie(autopct='%1.1f%%')
  plt.title('æ€§åˆ«å æ¯”')
  plt.ylabel('') # éšè—yè½´æ ‡ç­¾
  plt.show()
  ```

### 3ï¸âƒ£ æ•°æ®å»ºæ¨¡ (Modeling)

å°†å¤„ç†å¥½çš„æ•°æ®ç”¨äºæ„å»ºã€è®­ç»ƒå’Œæµ‹è¯•æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚

#### 3.1 ç‰¹å¾å·¥ç¨‹

- **è¿ç»­å˜é‡å¤„ç† (æ— é‡çº²åŒ–)**: æ¶ˆé™¤ä¸åŒç‰¹å¾é—´é‡çº²å’Œæ•°é‡çº§çš„å½±å“ã€‚

  - **æ ‡å‡†åŒ– (Standardization)**: é€‚ç”¨äºæ•°æ®è¿‘ä¼¼é«˜æ–¯åˆ†å¸ƒçš„æƒ…å†µã€‚

  ```python
  from sklearn.preprocessing import StandardScaler
  scaler = StandardScaler()
  df['age_scaled'] = scaler.fit_transform(df[['age']])
  ```

  - **å½’ä¸€åŒ– (Normalization)**: å°†æ•°æ®ç¼©æ”¾åˆ° [0, 1] åŒºé—´ï¼Œé€‚ç”¨äºè¾¹ç•Œæ˜æ˜¾çš„ç‰¹å¾ã€‚

  ```python
  from sklearn.preprocessing import MinMaxScaler
  scaler = MinMaxScaler()
  df['income_scaled'] = scaler.fit_transform(df[['income']])
  ```

- **ç¦»æ•£å˜é‡å¤„ç†**:

  - **ç‹¬çƒ­ç¼–ç  (One-Hot Encoding)**: å°†ç±»åˆ«å˜é‡è½¬æ¢ä¸ºå¤šä¸ª0/1å˜é‡ï¼Œé¿å…å¼•å…¥åºæ•°å…³ç³»ã€‚

  ```python
  # ä½¿ç”¨pandasçš„get_dummieså‡½æ•°
  df_dummies = pd.get_dummies(df, columns=['gender', 'city'], drop_first=True)
  ```

  - **æ ‡ç­¾ç¼–ç  (Label Encoding)**: å°†ç±»åˆ«è½¬ä¸ºæ•°å€¼ï¼Œé€‚ç”¨äºæœ‰åºç±»åˆ«æˆ–æ ‘æ¨¡å‹ã€‚

  ```python
  # ä½¿ç”¨pandasçš„factorize
  df['education_encoded'] = pd.factorize(df['education_level'])[0]
  ```

- **æ—¶é—´åºåˆ—å¤„ç†**:

  ```python
  df['date'] = pd.to_datetime(df['date_string'])
  df['year'] = df['date'].dt.year
  df['month'] = df['date'].dt.month
  ```

#### 3.2 ç‰¹å¾é€‰æ‹©

- **ç›¸å…³ç³»æ•°æ³•**: ä¼˜å…ˆé€‰æ‹©ä¸ç›®æ ‡å˜é‡ç›¸å…³æ€§é«˜çš„ç‰¹å¾ã€‚

  ```python
  # è®¡ç®—æ‰€æœ‰ç‰¹å¾ä¸ç›®æ ‡å˜é‡'target'çš„ç›¸å…³æ€§
  corr_target = df.corr(numeric_only=True)['target'].abs().sort_values(ascending=False)
  print(corr_target)
  ```

#### 3.3 æ•°æ®æ‹†åˆ†

å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œç”¨äºè®­ç»ƒæ¨¡å‹å’Œè¯„ä¼°å…¶æ³›åŒ–èƒ½åŠ›ã€‚

```python
from sklearn.model_selection import train_test_split

# å‡è®¾ 'target' æ˜¯å› å˜é‡ï¼Œå…¶ä½™æ˜¯è‡ªå˜é‡ X
X = df.drop('target', axis=1)
y = df['target']

# æŒ‰ç…§ 80% è®­ç»ƒé›†, 20% æµ‹è¯•é›†è¿›è¡Œæ‹†åˆ†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

#### 3.4 æ¨¡å‹é€‰æ‹©ä¸æ„å»º

æ ¹æ®é—®é¢˜ç±»å‹ï¼ˆå›å½’/åˆ†ç±»/èšç±»ï¼‰é€‰æ‹©åˆé€‚çš„ç®—æ³•ã€‚

- **å›å½’ (é¢„æµ‹æ•°å€¼)**: `LinearRegression`, `Ridge`, `Lasso`, `RandomForestRegressor`, `GradientBoostingRegressor`
- **åˆ†ç±» (é¢„æµ‹ç±»åˆ«)**: `LogisticRegression`, `KNeighborsClassifier`, `SVC`, `DecisionTreeClassifier`, `RandomForestClassifier`

**ç¤ºä¾‹ï¼šæ„å»ºéšæœºæ£®æ—åˆ†ç±»å™¨**

```python
from sklearn.ensemble import RandomForestClassifier

# 1. è°ƒç”¨æ¨¡å‹
model = RandomForestClassifier(n_estimators=100, random_state=42)

# 2. è®­ç»ƒæ¨¡å‹ (ä½¿ç”¨è®­ç»ƒé›†)
model.fit(X_train, y_train)

# 3. æ¨¡å‹é¢„æµ‹ (ä½¿ç”¨æµ‹è¯•é›†)
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1] # è·å–æ­£ç±»çš„é¢„æµ‹æ¦‚ç‡ï¼Œç”¨äºROC/KS
```

### 4ï¸âƒ£ æ¨¡å‹è¯„ä¼° (Evaluation)

é‡åŒ–æ¨¡å‹çš„æ€§èƒ½è¡¨ç°ã€‚

#### 4.1 å›å½’æ¨¡å‹è¯„ä¼°

```python
from sklearn.metrics import mean_squared_error, r2_score

# å‡æ–¹è¯¯å·® (MSE)ï¼Œè¶Šå°è¶Šå¥½
mse = mean_squared_error(y_test, y_pred)
print(f"å‡æ–¹è¯¯å·® (MSE): {mse:.4f}")

# å‡æ–¹æ ¹è¯¯å·® (RMSE)ï¼Œè¶Šå°è¶Šå¥½
rmse = np.sqrt(mse)
print(f"å‡æ–¹æ ¹è¯¯å·® (RMSE): {rmse:.4f}")

# Ræ–¹ (R-squared)ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½
r2 = r2_score(y_test, y_pred)
print(f"Ræ–¹ (RÂ²): {r2:.4f}")
```

#### 4.2 åˆ†ç±»æ¨¡å‹è¯„ä¼°

```python
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score

# å‡†ç¡®ç‡
accuracy = accuracy_score(y_test, y_pred)
print(f"å‡†ç¡®ç‡: {accuracy:.4f}")

# æ··æ·†çŸ©é˜µ
conf_matrix = confusion_matrix(y_test, y_pred)
print("æ··æ·†çŸ©é˜µ:\n", conf_matrix)

# ä½¿ç”¨çƒ­åŠ›å›¾å¯è§†åŒ–æ··æ·†çŸ©é˜µ
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('é¢„æµ‹å€¼')
plt.ylabel('çœŸå®å€¼')
plt.title('æ··æ·†çŸ©é˜µ')
plt.show()

# åˆ†ç±»æŠ¥å‘Š (åŒ…å«ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°)
class_report = classification_report(y_test, y_pred)
print("åˆ†ç±»æŠ¥å‘Š:\n", class_report)

# ROCæ›²çº¿å’ŒAUCå€¼
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
auc = roc_auc_score(y_test, y_pred_proba)

plt.plot(fpr, tpr, label=f'ROC æ›²çº¿ (AUC = {auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--') # éšæœºçŒœæµ‹çº¿
plt.xlabel('å‡æ­£ä¾‹ç‡ (FPR)')
plt.ylabel('çœŸæ­£ä¾‹ç‡ (TPR)')
plt.title('ROC æ›²çº¿')
plt.legend()
plt.show()
```

### 5ï¸âƒ£ æ¨¡å‹ä¼˜åŒ–ä¸æ€»ç»“

#### 5.1 æ¨¡å‹ä¼˜åŒ– (ç½‘æ ¼æœç´¢)

ä½¿ç”¨äº¤å‰éªŒè¯å’Œç½‘æ ¼æœç´¢æ¥å¯»æ‰¾æ¨¡å‹çš„æœ€ä½³è¶…å‚æ•°ç»„åˆã€‚

```python
from sklearn.model_selection import GridSearchCV

# å®šä¹‰è¦æœç´¢çš„å‚æ•°ç½‘æ ¼
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

# è®¾ç½®ç½‘æ ¼æœç´¢
# cv=5 è¡¨ç¤º5æŠ˜äº¤å‰éªŒè¯, n_jobs=-1 è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),
                           param_grid=param_grid,
                           cv=5,
                           scoring='accuracy',
                           verbose=1,
                           n_jobs=-1)

# åœ¨è®­ç»ƒæ•°æ®ä¸Šæ‰§è¡Œæœç´¢
grid_search.fit(X_train, y_train)

# è¾“å‡ºæœ€ä½³ç»“æœ
print(f"æœ€ä½³å‚æ•°: {grid_search.best_params_}")
print(f"æœ€ä½³äº¤å‰éªŒè¯å¾—åˆ†: {grid_search.best_score_:.4f}")

# ä½¿ç”¨æœ€ä½³æ¨¡å‹è¿›è¡Œé¢„æµ‹
best_model = grid_search.best_estimator_
# ... åç»­è¯„ä¼°
```

#### ğŸ“‹5.2 é¡¹ç›®æ€»ç»“

- **æœ€ä¼˜æ¨¡å‹**: æ˜ç¡®å“ªä¸ªæ¨¡å‹å’Œå“ªç»„å‚æ•°è¡¨ç°æœ€å¥½ã€‚
- **æ€§èƒ½è¡¨ç°**: æ€»ç»“æ¨¡å‹åœ¨å…³é”®è¯„ä¼°æŒ‡æ ‡ä¸Šçš„å…·ä½“æ•°å€¼ã€‚
- **æ¨¡å‹ä¸è¶³**: åˆ†ææ¨¡å‹çš„å±€é™æ€§ï¼Œä¾‹å¦‚åœ¨å“ªäº›æ•°æ®ä¸Šè¡¨ç°ä¸ä½³ï¼Œå¯èƒ½çš„åŸå› æ˜¯ä»€ä¹ˆã€‚
- **æ”¹è¿›æ–¹å‘**: æå‡ºæœªæ¥å¯ä»¥å°è¯•çš„æ”¹è¿›ç‚¹ï¼Œå¦‚è·å–æ›´å¤šç‰¹å¾ã€å°è¯•æ›´å¤æ‚çš„æ¨¡å‹ç­‰ã€‚
- **é¡¹ç›®æ”¶è·**: æ€»ç»“ä»é¡¹ç›®ä¸­å­¦åˆ°çš„çŸ¥è¯†å’Œç»éªŒã€‚