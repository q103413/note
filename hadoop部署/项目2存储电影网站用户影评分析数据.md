# 存储电影网站用户影评分析数据（Hadoop 实践）

## 一、项目背景

### 1.1 传统数据库的局限性

- 当用户影评数据规模达到**TB/PB 级**时，传统数据库（如 MySQL）处理能力不足，无法满足海量数据的存储与计算需求。

### 1.2 Hadoop 的解决方案

- Hadoop 是解决大数据计算的核心框架，核心设计为两大组件：
  1. **HDFS（Hadoop Distributed File System）**：负责分布式数据存储。
  2. **MapReduce**：负责并行数据计算。
- Hadoop 优势：支持普通服务器硬件，实现 “分布式存储 + 并行计算”，为后续影评数据分析奠定基础。

## 二、Hadoop 安全模式

### 2.1 安全模式定义与作用

- 安全模式是 Hadoop 的**保护机制**，保障文件系统不被破坏。
- 安全模式下，HDFS 仅接收**读数据请求**，拒绝删除、修改、新增数据等写操作。

### 2.2 安全模式的重要性（核心风险点）

1. **公共资源风险**：Hadoop 默认不验证用户，任何人可访问 HDFS，文件私密性无保障。
2. **伪装服务风险**：攻击者可伪装成 Hadoop 服务（如任务跟踪器）入侵集群。
3. **数据块访问无控制**：DataNode 不对数据块实施访问控制，未授权用户可获取任意数据块。

### 2.3 查看安全模式状态

- **触发场景**：
  1. Hadoop 集群启动时，会自动进入安全模式（检查 DataNode 数据块有效性）。
  2. 未关闭 Hadoop 直接关闭虚拟机，下次启动集群会持续处于安全模式（需手动解除）。
- **查看方式**：
  - 通过 HDFS 监控界面（`http://master:8088`）查看，关键信息：`Safe mode is ON/OFF`。
  - 界面会显示数据块达标情况（如 “需额外 215 个块达到总块数 216 的 99.9% 阈值”）。

### 2.4 安全模式的开启与解除（命令）

| 操作         | 命令                            |
| ------------ | ------------------------------- |
| 解除安全模式 | `hdfs dfsadmin -safemode leave` |
| 开启安全模式 | `hdfs dfsadmin -safemode enter` |

## 三、查看 Hadoop 集群基本信息

### 3.1 集群核心功能

Hadoop 集群的核心能力是**分布式存储**（HDFS）与**并行计算**（YARN+MapReduce），提交任务前需先确认资源状态。

### 3.2 查看存储系统信息（HDFS）

HDFS 由 1 个`NameNode`（管理元数据）和多个`DataNode`（存储数据块）组成，支持两种查询方式：

#### 3.2.1 浏览器方式（推荐）

- 访问地址：`http://master:9870`（NameNode 默认监控端口）。
- 操作：点击界面中**Utilities → Browse the file system**，可查看 HDFS 目录结构与文件列表。

#### 3.2.2 命令行方式

- 命令：`hdfs dfsadmin -report`。
- 作用：输出文件系统基本信息（如 DataNode 状态、存储容量）及统计数据。

#### 3.2.3 HDFS 关键统计信息解释

| 统计项              | 说明（示例值）                  |
| ------------------- | ------------------------------- |
| Configured Capacity | 已配置的总存储容量（50.96GB）   |
| DFS Used            | HDFS 已使用容量（2.38GB）       |
| Non DFS Used        | 非 HDFS 应用占用容量（11.27GB） |
| DFS Remaining       | HDFS 剩余容量（37.31GB）        |
| Live Nodes          | 在线 DataNode 数量（3 个）      |

### 3.3 查看计算资源信息（YARN）

计算资源由`ResourceManager`（资源调度）和`NodeManager`（节点管理）协同管理，主要通过浏览器查询：

#### 3.3.1 浏览器方式

- 访问地址：`http://master:8088/cluster/nodes`（YARN 默认监控端口）。

#### 3.3.2 计算资源关键信息解释

| 统计项            | 说明（示例值）                     |
| ----------------- | ---------------------------------- |
| Active Nodes      | 在线计算节点数量（3 个）           |
| Total Resources   | 总资源（memory:6GB，vCores:3）     |
| Rack              | 机架名称（默认`default-rack`）     |
| Containers        | 运行任务的容器数量（无任务时为 0） |
| Mem Used/Avail    | 内存使用 / 可用空间（如 0B/2GB）   |
| VCores Used/Avail | CPU 核心使用 / 可用数量（如 0/1）  |

## 四、上传文件到 HDFS 目录

### 4.1 HDFS 基础认知

- HDFS 采用**树状文件目录结构**，根目录为`/`，与 Linux 文件系统逻辑一致。
- 数据访问流程：本地计算机（Windows/macOS）→ Linux 集群节点 → HDFS。

### 4.2 文件上传完整流程（以`data.txt`为例）

1. **本地→Linux 节点**：用 SSH/FTP 工具将本地`E:\data.txt`上传至 Linux 节点的`/root/hadoop/`目录。
2. **Linux→HDFS**：在 Linux 终端用 HDFS 命令，将文件上传至 HDFS 目标目录（如`/user/root/`）。

### 4.3 HDFS 基本操作命令

| 操作类型        | 命令语法                                                     | 实例                                        |
| --------------- | ------------------------------------------------------------ | ------------------------------------------- |
| 创建目录        | `hdfs dfs -mkdir [-p] <path>`（`-p`支持多级目录）            | `hdfs dfs -mkdir -p /dfstest/test/example`  |
| 上传文件        | 1. `hdfs dfs -copyFromLocal <localsrc> <dst>`（复制）<br />2. `hdfs dfs -put <localsrc> <dst>`（移动） | `hdfs dfs -put /root/hadoop/a.txt /dfstest` |
| 下载文件        | 1. `hdfs dfs -copyToLocal <src> <localdst>`<br />2. `hdfs dfs -get <src> <localdst>` | `hdfs dfs -get /dfstest/a.txt /root/`       |
| 查看文件内容    | 1. `hdfs dfs -cat <src>`（全量查看）<br />2. `hdfs dfs -tail [-f] <file>`（查看末尾） | `hdfs dfs -cat /dfstest/a.txt`              |
| 删除文件 / 目录 | 1. `hdfs dfs -rm [-r] <src>`（`-r`递归删目录）<br />2. `hdfs dfs -rmdir <dir>`（删空目录） | `hdfs dfs -rm -r /dfstest/test`             |

## 五、运行 MapReduce 任务

### 5.1 MapReduce 核心作用

MapReduce 是 Hadoop 的数据处理引擎，通过 “分而治之” 的思想实现并行计算，适用于海量数据统计（如影评关键词频次、用户登录次数）。

### 5.2 Hadoop 官方示例程序包

- **包路径**：`$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar`。
- **常用模块说明**：

| 模块名称         | 功能说明                               |
| ---------------- | -------------------------------------- |
| wordcount        | 统计输入文件中单词的频次               |
| pi               | 用拟蒙特卡洛方法估算圆周率 π           |
| randomtextwriter | 在每个 DataNode 生成 10GB 随机文本文件 |
| wordmean         | 计算单词的平均长度                     |
| wordmedian       | 计算单词长度的中位数                   |

### 5.3 提交 MapReduce 任务（实例：统计用户登录次数）

#### 5.3.1 任务提交命令语法

```bash
hadoop jar <jar包路径> [主类名/模块名] <输入路径> <输出路径>
```

- 注意：输出路径**不能提前存在**（Hadoop 会自动创建，避免覆盖数据）。

#### 5.3.2 任务步骤

1. 上传日志文件：将`email_log.txt`上传至 HDFS 的`/dfstest`目录（用`hdfs dfs -put`命令）。

2. 执行统计命令：

   ```bash
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar wordcount /dfstest/email_log.txt /dfstest/login_count_output
   ```

3. 查看结果：

   - 命令行：`hdfs dfs -cat /dfstest/login_count_output/part-r-00000`。
   - Web 界面：通过`http://master:9870`浏览`/dfstest/login_count_output`目录，查看输出文件。

## 六、管理多个 MapReduce 任务

### 6.1 多任务管理入口

通过 YARN 监控界面管理：`http://master:8088/cluster/apps`，可查看所有任务的状态（提交 / 运行 / 完成 / 失败）。

### 6.2 多任务资源占用特性

- 当多个任务同时提交时，先执行的任务会占用集群资源（内存、CPU）。
- 若前序任务占用资源多、执行时间长，后续任务会进入**等待状态（ACCEPTED）**。

### 6.3 中断 MapReduce 任务（步骤）

当任务异常、耗时过长或占用资源过多时，需手动中断：

1. 访问`http://master:8088/cluster/apps`，找到目标任务（如`QuasiMonteCarlo`）。
2. 点击任务 ID（如`application_1715130798131_0004`），进入任务详情页。
3. 点击左上角**Kill Application**，在弹窗中确认，任务状态变为`KILLED`。
4. 后续等待任务会自动切换为`RUNNING`状态，占用释放的资源。

## 七、项目实践：上传用户影评数据到 HDFS

### 7.1 实践目标

将 3 份用户影评数据（`ratings.dat`、`users.dat`、`movies.dat`）上传至 HDFS，为后续影评分析（如用户偏好、电影评分统计）准备数据。

### 7.2 实践流程

1. **本地→Linux**：用 SSH/FTP 工具将 3 个.dat 文件上传至 Linux 节点的`/root/movie_data/`目录。

2. **创建 HDFS 目录**：`hdfs dfs -mkdir -p /Uname/Hadoop/MapReduce`。

3. **Linux→HDFS**：执行上传命令：

   ```bash
hdfs dfs -put /root/movie_data/*.dat /Uname/Hadoop/MapReduce
   ```

4. **验证结果**：通过`http://master:9870`浏览`/Uname/Hadoop/MapReduce`目录，确认 3 个文件已上传。

## 八、项目总结

1. **核心知识**：掌握 Hadoop 安全模式管理、集群资源查询、HDFS 操作、MapReduce 任务提交与中断。
2. **关键技能**：
   - HDFS 命令：`mkdir`/`put`/`get`/`cat`，解决数据存储问题。
   - MapReduce 任务：利用官方示例包实现基础统计，理解并行计算逻辑。
3. **实践价值**：完成影评数据上传，为后续 MapReduce 编程分析（如用户评分分布、热门电影统计）奠定数据基础。
