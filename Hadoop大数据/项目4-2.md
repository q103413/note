我已阅读完你上传的《项目4 多维度分析电影网站用户影评.pptx》内容。下面是对该资料的**总结、优化与系统化整理**，我帮你把它改写成一篇完整、结构清晰、可作为**学习教程**或教学讲义使用的文本。

------

# **项目四：多维度分析电影网站用户影评——MapReduce 综合实战教程**

## 一、项目背景

随着电影产业的快速发展，在线电影平台积累了海量用户影评与评分数据。如何从这些非结构化数据中挖掘出有价值的信息，成为影视制作方、发行方和流媒体平台的重要课题。

本项目以 **Hadoop MapReduce 编程框架** 为核心，利用其分布式并行计算能力，对电影网站影评数据进行多维度分析，实现以下目标：

1. 统计评分次数最多的 10 部电影；
2. 分析不同性别用户评分最高的 10 部电影；
3. 计算指定电影在各年龄段用户中的平均评分；
4. 统计不同电影类型中评分最高的 5 部电影。

本教程将通过完整的 Hadoop MapReduce 实战，涵盖输入输出格式设置、Hadoop Java API 文件操作、自定义类型、Combiner 与 Partitioner 优化、计数器使用，以及在 IntelliJ IDEA 中自动打包与提交作业等内容。

------

## 二、核心技术与环境

- **编程框架**：Hadoop MapReduce
- **开发语言**：Java
- **开发工具**：IntelliJ IDEA
- **运行环境**：Hadoop 集群（HDFS + YARN）
- **数据来源**：电影网站影评数据集（movies.dat、ratings.dat、users.dat）

------

## 三、实验目标与内容

| 模块         | 实验目标                                  | 涉及技术                                  |
| ------------ | ----------------------------------------- | ----------------------------------------- |
| 输入输出格式 | 掌握序列化文件（SequenceFile）读写        | TextInputFormat、SequenceFileInputFormat  |
| 文件操作     | 使用 Hadoop Java API 管理文件系统         | FileSystem API、mkdirs、copyFromLocalFile |
| 性能优化     | 学习 Combiner、Partitioner、自定义计数器  | WritableComparable、Combiner、Partitioner |
| 程序提交     | 实现 IDEA 中自动打包与运行 MapReduce 程序 | ToolRunner、Configuration、JarUtil        |
| 项目实践     | 实现多维度影评分析                        | MapReduce 综合编程                        |

------

## 四、MapReduce 输入与输出格式设置

### 1. 输入格式

Hadoop 提供多种输入格式，常见有：

- **TextInputFormat（默认）**：每行一个键值对，键为行偏移量。
- **KeyValueTextInputFormat**：以分隔符划分的键值对。
- **SequenceFileInputFormat**：用于读取二进制序列化文件，性能更高，适合多次作业串联。

👉 使用方法：

```java
job.setInputFormatClass(SequenceFileInputFormat.class);
```

### 2. 输出格式

常见输出格式包括：

- **TextOutputFormat**：默认文本输出；
- **SequenceFileOutputFormat**：输出为序列化文件；
- **NullOutputFormat**：忽略输出。

👉 设置方法：

```java
job.setOutputFormatClass(SequenceFileOutputFormat.class);
```

------

## 五、使用 Hadoop Java API 操作文件系统

### 1. 获取 FileSystem 实例

```java
Configuration conf = new Configuration();
FileSystem fs = FileSystem.get(conf);
```

### 2. 常用操作方法

| 方法                                    | 功能           |
| --------------------------------------- | -------------- |
| `mkdirs(Path dir)`                      | 创建目录       |
| `delete(Path f, boolean recursive)`     | 删除文件或目录 |
| `copyFromLocalFile(Path src, Path dst)` | 上传文件       |
| `copyToLocalFile(Path src, Path dst)`   | 下载文件       |
| `open(Path f)` / `create(Path f)`       | 文件读写流     |

这些 API 在 MapReduce 前后数据准备与结果查看中非常实用。

------

## 六、MapReduce 性能优化技术

### 1. 自定义键值类型（WritableComparable）

适用于多字段复合排序场景，例如统计「用户ID + 日期」访问次数。

需要实现：

```java
public class MyKey implements WritableComparable<MyKey> {
    private Text userId;
    private Text date;
    public void write(DataOutput out) {...}
    public void readFields(DataInput in) {...}
    public int compareTo(MyKey o) {...}
}
```

### 2. Combiner（本地合并器）

用于在 Map 阶段结束前对中间结果进行本地聚合，减少网络传输。

> 仅适用于可交换、可结合的运算（如求和、计数、最大值等）。

配置：

```java
job.setCombinerClass(MyCombiner.class);
```

### 3. Partitioner（自定义分区）

用于控制键值对进入哪个 Reducer，常用于按月份、类型或区域划分。

```java
public class MyPartitioner extends Partitioner<Text, IntWritable> {
    public int getPartition(Text key, IntWritable value, int numReduceTasks) {
        return key.toString().substring(5,7).equals("01") ? 0 : 1;
    }
}
job.setPartitionerClass(MyPartitioner.class);
job.setNumReduceTasks(2);
```

### 4. 自定义计数器

可用于统计任务执行状态或数据分布。

```java
enum MyCounter { TOTAL_RECORDS, INVALID_LINES }
context.getCounter(MyCounter.TOTAL_RECORDS).increment(1);
```

------

## 七、IDEA 中自动打包与远程提交 MapReduce 程序

传统方式需要手动：

> 编译 → 打包 Jar → 上传至集群 → 命令行执行

优化后可通过：

- 在 IDEA 中配置 Hadoop 集群连接；
- 编写 `JarUtil` 工具类实现自动打包；
- 使用 `ToolRunner` 简化参数传递与执行。

示例：

```java
public class MyDriver extends Configured implements Tool {
    public int run(String[] args) {
        Job job = Job.getInstance(getConf(), "MovieRateJob");
        ...
        return job.waitForCompletion(true) ? 0 : 1;
    }
    public static void main(String[] args) throws Exception {
        int res = ToolRunner.run(new Configuration(), new MyDriver(), args);
        System.exit(res);
    }
}
```

------

## 八、项目实践：多维度影评分析

### 1. 统计评分次数最多的 10 部电影

- Map 阶段：统计每部电影的评分次数；
- Reduce 阶段：聚合后降序排序；
- 输出：Top 10 电影及其评分次数。

### 2. 分析不同性别用户评分最高的 10 部电影

- 将用户表与评分表连接；
- 按性别分组；
- 计算平均评分并取前 10。

### 3. 计算指定电影的各年龄段平均评分

- 连接 `movies.dat`、`ratings.dat`、`users.dat`；
- 过滤特定 `movieID`；
- 按年龄段聚合求平均。

### 4. 各电影类型评分最高的 5 部电影

- 按类型分组；
- 求各类型下平均评分；
- 输出前 5 条。

------

## 九、项目总结与扩展

本项目通过 MapReduce 实现了从**评分次数、性别、年龄段、类型**四个维度的用户偏好分析。
 掌握了以下关键技能：

| 技能点                  | 实际应用             |
| ----------------------- | -------------------- |
| MapReduce 输入/输出格式 | 高效存储与多任务衔接 |
| Hadoop Java API         | 文件上传、删除、读取 |
| 自定义类型与排序        | 多维字段组合统计     |
| Combiner / Partitioner  | 任务性能优化         |
| ToolRunner / IDEA 集成  | 自动化提交与运行     |

🔧 **可扩展方向**：

- 使用 Spark 实现同样分析任务；
- 引入 Hive / Pig 进行交互式分析；
- 使用可视化工具展示用户偏好。

------

## 十、学习建议

1. 先理解 MapReduce 运行原理，再动手编写；
2. 熟悉 HDFS 命令行与 FileSystem API；
3. 在每次实验后使用日志与计数器验证结果；
4. 尝试用不同输入输出格式比较性能差异；
5. 最终结合多维数据分析，形成完整的报表或仪表盘。

------

✅ **附加资料建议**

- 《Hadoop 权威指南（第4版）》
- 官方文档：https://hadoop.apache.org/docs/
- 实战项目可使用 MovieLens 数据集验证。

------

是否希望我帮你把这份教程再**排版成 Markdown 或 PDF 学习手册版本**（可直接打印或发学生使用）？
 我可以帮你生成一份正式版的教学讲义文件。