下面是一篇根据你提供的 PPT 内容，**总结优化、注重实操**的完整学习教程：《基于 Hive 的电影网站数据仓库实战教程》。内容融合理论讲解与命令示例，适合动手实操学习。

------

# 🧠 基于 Hive 的电影网站数据仓库实战教程

## 一、项目背景

随着电影网站业务规模的扩大，用户影评、影片信息和评分数据量不断增加。传统数据库已难以高效处理海量数据，因此企业普遍转向使用 **Hive** 构建数据仓库，以便进行离线分析与决策支持。

Hive 依托 Hadoop 的分布式架构，支持使用类 SQL 的 HQL 语句高效查询和分析 TB/PB 级数据，非常适合电影网站这类大数据分析场景。

------

## 二、环境搭建与 Hive 安装实操

### 1. 安装模式概览

| 模式           | 元数据库               | 特点                   | 场景     |
| -------------- | ---------------------- | ---------------------- | -------- |
| 内嵌模式       | Derby                  | 安装简单，不共享元数据 | 测试学习 |
| 直连数据库模式 | MySQL                  | 元数据共享，单节点     | 小型集群 |
| 远程模式       | MySQL + MetaStore 服务 | 支持多节点访问         | 生产环境 |

------

### 2. 内嵌模式安装步骤（快速上手）

#### （1）上传并解压 Hive 安装包

```bash
cd /opt/apps
tar -zxvf apache-hive-3.1.3-bin.tar.gz -C /usr/local/
```

#### （2）替换依赖解决冲突

删除旧 guava 包、复制 Hadoop 的 guava：

```bash
cd /usr/local/apache-hive-3.1.3-bin/lib
rm guava-19.0.jar
cp /usr/local/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar .
```

#### （3）配置环境变量

编辑 `/etc/profile`：

```bash
export HIVE_HOME=/usr/local/apache-hive-3.1.3-bin
export PATH=$PATH:$HIVE_HOME/bin
```

加载：

```bash
source /etc/profile
```

#### （4）启动 Hive

确保 Hadoop 集群已启动：

```bash
start-dfs.sh
start-yarn.sh
```

然后执行：

```bash
hive
show databases;
```

------

### 3. 直连 MySQL 模式（生产常用）

#### （1）安装 MySQL

```bash
rpm -ivh mysql-community-common-8.0.21-1.el7.x86_64.rpm
rpm -ivh mysql-community-libs-8.0.21-1.el7.x86_64.rpm
rpm -ivh mysql-community-client-8.0.21-1.el7.x86_64.rpm
rpm -ivh mysql-community-server-8.0.21-1.el7.x86_64.rpm
systemctl start mysqld
```

查看初始密码：

```bash
grep 'temporary password' /var/log/mysqld.log
```

#### （2）创建 Hive 元数据库

```sql
CREATE DATABASE hive DEFAULT CHARACTER SET utf8mb4;
```

#### （3）配置 `hive-site.xml`

```xml
<property>
  <name>javax.jdo.option.ConnectionURL</name>
  <value>jdbc:mysql://localhost:3306/hive?useSSL=false</value>
</property>
<property>
  <name>javax.jdo.option.ConnectionUserName</name>
  <value>root</value>
</property>
<property>
  <name>javax.jdo.option.ConnectionPassword</name>
  <value>你的密码</value>
</property>
```

#### （4）初始化元数据库

```bash
schematool -dbType mysql -initSchema
```

------

## 三、Hive 表操作实战

### 1. 创建数据库

```sql
CREATE DATABASE IF NOT EXISTS film;
USE film;
```

### 2. 创建内部表与外部表

#### （1）内部表

```sql
CREATE TABLE user_info (
  id INT,
  name STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t'
STORED AS TEXTFILE;
```

#### （2）外部表

上传文件：

```bash
hdfs dfs -mkdir /data/students
hdfs dfs -put student_info.txt /data/students/
```

创建外部表：

```sql
CREATE EXTERNAL TABLE student_info(
  id INT,
  name STRING,
  gender STRING,
  phone STRING,
  class STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LOCATION '/data/students/';
```

删除外部表不会删除 HDFS 文件。

------

### 3. 创建分区表（提高查询效率）

```sql
CREATE TABLE stu_score(
  id INT,
  course STRING,
  score FLOAT
)
PARTITIONED BY (class_name STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t';
```

添加分区：

```sql
ALTER TABLE stu_score ADD PARTITION (class_name='07111301');
```

------

### 4. 修改与删除表

```sql
ALTER TABLE stu_score RENAME TO student_score;
ALTER TABLE student_score ADD COLUMNS (gpa FLOAT);
DROP TABLE student_score;
```

------

## 四、数据操作实操（增删查改）

### 1. 装载数据

```sql
LOAD DATA LOCAL INPATH '/opt/stu/student.txt' INTO TABLE student_info;
```

### 2. 查询数据

```sql
SELECT id, name FROM student_info;
SELECT * FROM student_info WHERE gender='男';
```

### 3. 分组统计与排序

```sql
-- 每个课程的选课人数
SELECT course, COUNT(*) AS count FROM sc GROUP BY course;

-- 成绩大于90的学生
SELECT s.name, sc.score
FROM student_info s JOIN sc ON s.id = sc.id
WHERE sc.score > 90
ORDER BY sc.score DESC;
```

### 4. 插入与删除数据

#### 插入

```sql
INSERT INTO TABLE student_info VALUES (1001, '张华', '男', '18800001111', '07111301');
```

#### 删除（事务表）

启用事务后：

```sql
CREATE TABLE student_orc(
  id INT,
  name STRING
)
CLUSTERED BY (id) INTO 2 BUCKETS
STORED AS ORC
TBLPROPERTIES ('transactional'='true');

DELETE FROM student_orc WHERE id=2018213223;
```

------

## 五、电影网站影评分析实战

### 1. 数据表设计

```sql
CREATE DATABASE film;
USE film;

CREATE TABLE ratings (
  user_id INT,
  movie_id INT,
  rating FLOAT,
  timestamp STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '::';

CREATE TABLE users (
  user_id INT,
  gender STRING,
  age INT,
  occupation STRING,
  zip STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '::';

CREATE TABLE movies (
  movie_id INT,
  title STRING,
  genres STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '::';
```

### 2. 数据装载

```bash
LOAD DATA LOCAL INPATH '/opt/film/ratings.dat' INTO TABLE ratings;
LOAD DATA LOCAL INPATH '/opt/film/users.dat' INTO TABLE users;
LOAD DATA LOCAL INPATH '/opt/film/movies.dat' INTO TABLE movies;
```

------

### 3. 数据分析任务

#### （1）评分次数最多的 10 部电影

```sql
SELECT m.title, COUNT(r.rating) AS total_ratings
FROM ratings r JOIN movies m ON r.movie_id=m.movie_id
GROUP BY m.title
ORDER BY total_ratings DESC
LIMIT 10;
```

#### （2）不同性别评分最高的 10 部电影

```sql
SELECT u.gender, m.title, AVG(r.rating) AS avg_rating
FROM ratings r
JOIN users u ON r.user_id=u.user_id
JOIN movies m ON r.movie_id=m.movie_id
GROUP BY u.gender, m.title
ORDER BY avg_rating DESC
LIMIT 10;
```

#### （3）计算某电影不同年龄段平均评分

```sql
SELECT u.age, AVG(r.rating) AS avg_rating
FROM ratings r
JOIN users u ON r.user_id=u.user_id
WHERE r.movie_id=1
GROUP BY u.age;
```

#### （4）各类型电影评分最高前 5 名

```sql
SELECT m.genres, m.title, AVG(r.rating) AS avg_rating
FROM ratings r
JOIN movies m ON r.movie_id=m.movie_id
GROUP BY m.genres, m.title
ORDER BY avg_rating DESC
LIMIT 5;
```

------

## 六、项目总结

本项目从理论到实操系统讲解了 Hive 在电影网站中的应用：

1. 掌握 Hive 三种安装方式；
2. 熟悉数据库与表的创建、修改、分区；
3. 实现数据装载、查询、聚合统计；
4. 通过 HQL 完成电影评分分析，实现大数据分析的全流程。

> ✅ **延伸实操建议**：
>
> - 将分析结果导出为 Parquet 文件，提高查询性能；
> - 结合 Spark SQL 做二次分析或机器学习预测。

------

是否希望我帮你把这篇教程格式化成 **Markdown 学习笔记（带目录和命令块）** 或者 **PDF 学习文档**？