# 基于 Hive 的电影网站用户影评分析实操教程

本教程围绕 “Hive 实现电影网站用户影评分析” 展开，从 Hive 基础认知到实操落地，全程聚焦实操步骤与效果验证，帮助学习者快速掌握 Hive 在海量数据存储与分析中的核心应用。

## 一、教程核心目标

1. 理解 Hive 数据仓库的核心特性与适用场景，明确其与传统数据库的差异。
2. 掌握 Hive 三种安装模式的部署配置，能独立完成环境搭建。
3. 熟练运用 HQL 语句实现表的创建、修改及数据的增删查改操作。
4. 结合电影影评数据场景，完成真实业务数据分析，落地数据处理全流程。

## 二、前置准备

1. 环境要求：Linux 系统（推荐 CentOS 7）、Hadoop 3.x 集群、JDK 1.8、MySQL 8.0（用于直连 / 远程模式）。
2. 工具准备：Xftp（文件传输）、Xshell（远程连接）、Web UI（Hadoop/Hive 可视化查看）。
3. 数据准备：电影影评相关文件（ratings.dat、users.dat、movies.dat），包含用户 ID、电影 ID、评分、性别、电影类型等字段。

## 三、Hive 基础认知（实操前必懂）

### 1. 核心概念

Hive 是基于 Hadoop 的离线数据仓库工具，支持用 HQL（类 SQL）操作海量数据，适用于大规模数据集的存储与批量分析，不适合实时查询场景。

### 2. 与传统数据库的关键差异

| 对比维度 | Hive                   | 传统数据库（如 MySQL） |
| -------- | ---------------------- | ---------------------- |
| 数据存储 | HDFS 分布式存储        | 本地文件系统 / 块设备  |
| 执行引擎 | MapReduce/Tez/Spark    | 自身执行引擎           |
| 处理规模 | 海量数据（TB/PB 级）   | 中小规模数据           |
| 执行延迟 | 高（离线处理）         | 低（实时处理）         |
| 索引支持 | 0.8 版本后支持位图索引 | 支持复杂索引           |

### 3. 数据模型核心组件

- 数据库：逻辑隔离容器，与传统数据库的 Database 功能一致。
- 表：分为内部表（删表时删除数据 + 元数据）和外部表（删表仅删元数据）。
- 分区：按指定字段分目录存储，提升查询效率（如按电影类型分区）。
- 桶：对分区进一步细分，优化采样与 join 操作效率。

## 四、Hive 环境搭建实操（三种安装模式）

### 1. 内嵌模式（快速测试用）

#### 操作步骤

1. 下载 Hive 3.1.3 安装包，通过 Xftp 上传至 Linux 的 /opt/apps 目录。
2. 解压安装包到 /usr/local：`tar -zxvf apache-hive-3.1.3-bin.tar.gz -C /usr/local/`。
3. 解决 Jar 包冲突：删除 Hive 的 guava-19.0.jar，复制 Hadoop 的 guava-27.0-jre.jar 到 Hive 的 lib 目录。
4. 配置环境变量：编辑 /etc/profile，添加`export HIVE_HOME=/usr/local/apache-hive-3.1.3-bin`和`export PATH=$PATH:$HIVE_HOME/bin`，执行`source /etc/profile`生效。
5. 初始化元数据库：`schematool -dbType derby -initSchema`。
6. 启动 Hadoop 集群后，输入`hive`命令进入交互界面，验证`show databases;`是否正常执行。

#### 注意事项

- 内嵌模式元数据不共享，切换目录启动 Hive 会创建新数据库，仅适用于单机测试。

### 2. 直连数据库模式（本地生产用）

#### 操作步骤

1. 安装 MySQL：上传 4 个 RPM 包（client、common、libs、server），按顺序安装`rpm -ivh 包名`，启动 MySQL 并修改初始密码。
2. 配置 MySQL 远程访问：`grant all privileges on *.* to 'root'@'%' identified by '密码';`，刷新权限`flush privileges;`。
3. 配置 Hive：上传 Hive 安装包到 slave1 节点，解压并解决 Jar 包冲突（同内嵌模式）。
4. 上传 MySQL 连接 Jar 包（mysql-connector-java-8.0.21.jar）到 Hive 的 lib 目录。
5. 创建 hive-site.xml 文件，添加 MySQL 连接配置（URL、用户名、密码）。
6. 初始化元数据库：`schematool -dbType mysql -initSchema`，启动 Hive 验证连接。

#### 核心优势

- 元数据存储在 MySQL，支持多节点共享，适合单机生产环境。

### 3. 远程模式（集群协作用）

#### 操作步骤

1. 复制 slave1 的 Hive 目录到 slave2、slave3 节点：`scp -r /usr/local/apache-hive-3.1.3-bin slave2:/usr/local/`。
2. 配置 slave2、slave3 的环境变量（同 slave1）。
3. 修改 slave2 的 hive-site.xml，指定元数据服务地址为 slave2。
4. 在 slave2 初始化元数据库（需先删除原有 Hive 数据库），启动元数据服务：`hive --service metastore`。
5. 在 slave3 输入`hive`命令，验证是否能访问 slave2 的元数据。

## 五、HQL 核心操作实操

### 1. 数据库操作

```sql
-- 创建数据库（避免重复创建）
create database if not exists myhive;
-- 切换数据库
use myhive;
-- 删除数据库（空库直接删，非空需加cascade）
drop database if exists myhive cascade;
```

### 2. 表操作

#### （1）创建内部表

```sql
-- 创建用户信息内部表
create table if not exists user_info(
id int,
name string
)
row format delimited fields terminated by '\t'
stored as textfile;
```

#### （2）创建外部表

```sql
-- 基于student_info.txt创建外部表
create external table if not exists student_external(
stu_no string,
stu_name string,
stu_sex string,
telephone string,
stu_class string
)
row format delimited fields terminated by ','
location '/stu/'; -- HDFS中数据文件路径
```

#### （3）创建分区表

```sql
-- 创建按班级分区的成绩表
create table if not exists score_partition(
stu_no string,
cla_no string,
grade float
)
partitioned by (class_name string)
row format delimited fields terminated by '\t';
```

#### （4）表修改操作

```sql
-- 重命名表
alter table score_partition rename to stu_score;
-- 添加列
alter table stu_score add columns (credit float, gpa float);
-- 修改列名与类型
alter table stu_score change column credit Credits float;
-- 添加分区
alter table stu_score add partition (class_name='07111301');
```

### 3. 数据操作

#### （1）数据装载

```sql
-- 从本地文件装载数据到表
load data local inpath '/opt/stu/student.txt' into table student;
-- 从HDFS文件装载数据（移动文件）
load data inpath '/stu/course.txt' into table course;
```

#### （2）数据查询

```sql
-- 基础查询：查询所有学生学号和姓名
select stu_no, stu_name from student;
-- 条件查询：查询男生信息
select * from student where stu_sex='男';
-- 关联查询：查询学生选课成绩
select s.stu_name, c.course_name, sc.grade 
from student s 
join sc on s.stu_no=sc.stu_no 
join course c on sc.cla_no=c.course_no;
-- 分组统计：统计各课程选课人数
select cla_no, count(stu_no) as num from sc group by cla_no;
-- 排序查询：按学号升序排列
select * from student order by stu_no asc;
```

#### （3）数据插入与删除

```sql
-- 插入数据（不覆盖原有数据）
insert into table student values ('2018213223', '王小哲', '男', 18, 'IS');
-- 覆盖插入数据
insert overwrite table student select * from student_backup;
-- 删除数据（需创建事务表）
create table student_orc stored as orc tblproperties ('transactional'='true') as select * from student;
delete from student_orc where stu_no='2018213223';
```

## 六、电影影评数据分析项目实操

### 1. 项目需求

基于 ratings.dat、users.dat、movies.dat 三个文件，完成：

- 统计评分次数最多的 10 部电影
- 分析不同性别用户评分最高的 10 部电影
- 计算指定电影各年龄段平均评分
- 统计各类型电影评分最高的 5 部作品

### 2. 实操步骤

#### （1）创建数据库与数据表

```sql
-- 创建电影分析数据库
create database if not exists film_analysis;
use film_analysis;

-- 创建评分表（处理::分隔符）
create table if not exists film.ratings(
UserID int,
MovieID int,
Rating int,
ts bigint
)
row format serde 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
with serdeproperties (
'field.delim'='::',
'serialization.format'='::'
)
stored as textfile;

-- 创建用户表
create table if not exists film.users(
UserID int,
Gender string,
Age int,
Occupation int,
Zip_code string
)
row format serde 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
with serdeproperties (
'field.delim'='::',
'serialization.format'='::'
)
stored as textfile;

-- 创建电影表
create table if not exists film.movies(
MovieID int,
MovieType string
)
row format serde 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
with serdeproperties (
'field.delim'='::',
'serialization.format'='::'
)
stored as textfile;
```

#### （2）导入数据

```sql
-- 从HDFS导入数据（先将文件上传至HDFS的/film目录）
load data inpath '/film/ratings.dat' into table film.ratings;
load data inpath '/film/users.dat' into table film.users;
load data inpath '/film/movies.dat' into table film.movies;
```

#### （3）核心分析查询

1. 评分次数最多的 10 部电影

```sql
select m.MovieID, count(r.Rating) as rating_count
from film_ratings r
join film_movies m on r.MovieID=m.MovieID
group by m.MovieID
order by rating_count desc
limit 10;
```

1. 不同性别用户评分最高的 10 部电影

```sql
select u.Gender, m.MovieID, avg(r.Rating) as avg_rating
from film_ratings r
join film_users u on r.UserID=u.UserID
join film_movies m on r.MovieID=m.MovieID
group by u.Gender, m.MovieID
order by u.Gender, avg_rating desc
limit 20; -- 男女各10部
```

1. 指定电影（如 MovieID=1）各年龄段平均评分

```sql
select u.Age, avg(r.Rating) as avg_rating
from film.ratings r
join film.users u on r.UserID=u.UserID
where r.MovieID=1
group by u.Age
order by u.Age;
```

1. 各类型电影评分最高的 5 部

```sql
select m.MovieType, m.MovieID, avg(r.Rating) as avg_rating
from film.ratings r
join film.movies m on r.MovieID=m.MovieID
group by m.MovieType, m.MovieID
order by m.MovieType, avg_rating desc
limit 5;
```

#### （4）结果保存

```sql
-- 将评分次数最多的电影结果保存为新表
create table top10_rated_movies as
select m.MovieID, count(r.Rating) as rating_count
from film.ratings r
join film.movies m on r.MovieID=m.MovieID
group by m.MovieID
order by rating_count desc
limit 10;
```

## 七、常见问题与排查

1. Hive 启动报错 “guava 版本冲突”：确认已替换 Hive 的 guava.jar 为 Hadoop 对应版本。
2. 无法连接 MySQL：检查 MySQL 服务是否启动，hive-site.xml 中连接 URL、用户名密码是否正确。
3. 数据查询为 null：确认建表时的分隔符与数据文件一致（如::、\t、,）。
4. 分区表查询无结果：需先添加分区再装载数据，或装载时指定分区`load data inpath '' into table xxx partition(class_name='xxx')`。

## 八、实操总结

本教程从环境搭建到项目落地，覆盖了 Hive 的核心实操场景。重点掌握 Hive 安装配置、HQL 表操作与数据处理，以及多表关联分析的思路。电影影评分析案例验证了 Hive 在海量数据处理中的高效性，实际应用中可根据业务需求调整表结构与查询逻辑。

要不要我帮你整理一份**Hive 实操命令速查表**，包含安装、表操作、数据处理、故障排查的核心命令，方便你随时查阅？